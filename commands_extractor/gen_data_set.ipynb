{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    ! this file is supposed to generate text data that contains these types of words:\\n        ? action: a verb that describes the action the robot is supposed to do (turn, move...)\\n        ? subject: how the robot is supposed to do the action (lift, square...)\\n        ? unit: if a measure of time or distance is needed \\n        ? value: value of time of distance\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ! this file is supposed to generate text data that contains these types of words:\n",
    "        ? action: a verb that describes the action the robot is supposed to do (turn, move...)\n",
    "        ? subject: how the robot is supposed to do the action (lift, square...)\n",
    "        ? unit: if a measure of time or distance is needed \n",
    "        ? value: value of time of distance\n",
    "\"\"\"\n",
    "\n",
    "#! \n",
    "    #! The generated dataset will contain a lot of duplicates when the number of commands goes up, consider adding more more rules and using relatively small number\n",
    "#!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from jetbot_mini.msg import Commands_msg\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator:\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        self.actions = ['move', 'turn', 'advance', 'make a turn', 'make', 'keep moving', 'draw', 'write', 'move in the shape of', 'write the letter']\n",
    "\n",
    "        self.subjects = ['forward', 'backward', 'left', 'right', 'circle', 'circle with radius','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'right angle', 'left angle']\n",
    "\n",
    "        self.units = [\"meters\", \"seconds\", 'degrees']\n",
    "\n",
    "        self.values = np.arange(0, 100,0.25)\n",
    "\n",
    "        self.action_classes = {\"straight\": ['move', 'advance', 'keep moving'],\n",
    "                               \"turns\": ['turn', 'make a turn', 'make'],\n",
    "                               \"shapes\": ['draw', 'write', 'move in the shape of', 'write the letter']}\n",
    "\n",
    "        self.subject_classes = {\"shapes\": ['circle', 'circle with radius','A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n",
    "                                \"directions\":['forward', 'backward', 'left', 'right'],\n",
    "                                \"angles\": ['right angle', 'left angle']}\n",
    "\n",
    "        self.unit_classes = {\"distance\": ['m', 'meter', 'meters'],\n",
    "                             \"time\": ['s', 'second', 'seconds', 'm', 'minute', 'minutes'],\n",
    "                             \"angle\": ['d', 'deg', 'degree', 'degrees', 'r', 'rad', 'radian', 'radians']\n",
    "                             }\n",
    "        \n",
    "        self.value_classes = {\"value\": self.values}\n",
    "\n",
    "\n",
    "        self.rules = {\"<START>,<A>straight\": ['<S>directions'],\n",
    "                      \"<A>straight,<S>directions\":['<V>value'],\n",
    "                      \"<S>directions,<V>Value\": ['<U>time', '<U>distance'],\n",
    "                      \"<V>Value,<U>time\":['<END>'],\n",
    "                      \"<V>Value,<U>distance\":['<END>'],\n",
    "\n",
    "                      \"<START>,<A>turns\": [\"<S>directions(left|right)\"],\n",
    "                      \"<A>turns,<S>directions(left|right)\": ['<V>value'],\n",
    "                      \"<S>directions(left|right),<V>value\":['<U>angle'],\n",
    "                      \"<V>value,<U>angle\":['<END>'],\n",
    "\n",
    "                      \"<START>,<A>shapes\": ['<S>shapes'],\n",
    "                      \"<A>shapes,<S>shapes\": [\"<END>\"]}\n",
    "\n",
    "        self.class_symbols = {\"<A>\": self.action_classes, \"<S>\": self.subject_classes, \"<V>\": self.value_classes, \"<U>\": self.unit_classes}\n",
    "\n",
    "    def decode_token(self, token):\n",
    "        if token == \"<END>\":\n",
    "            return {\"class\": \"deliminer\", \"value\": 'end'}\n",
    "\n",
    "        elif token == \"<START>\":\n",
    "            return {\"class\": \"deliminer\", \"value\": 'start'}\n",
    "\n",
    "        else:\n",
    "            token_class_symbol = token[:3]\n",
    "            token_class = self.class_symbols.get(token_class_symbol)\n",
    "            value = token[3:]\n",
    "            enumerations = []\n",
    "            if '|' in token:\n",
    "                    enumerations = token.split('(')[1].split(')')[0].split('|')\n",
    "            return {\"class\": token_class, \"value\": value, \"enumerations\": enumerations}\n",
    "\n",
    "    def get_value_from_token(self, token):\n",
    "        if token != \"<END>\":\n",
    "            token_class_symbol = token[:3]\n",
    "            token_class = self.class_symbols.get(token_class_symbol)\n",
    "            enumerations = []\n",
    "            if '|' in token:\n",
    "                enumerations = token.split('(')[1].split(')')[0].split('|')\n",
    "            token = token[3:]\n",
    "            token_values = token_class.get(token)\n",
    "            random_value = str(np.random.choice(token_values)) if len(enumerations) == 0 else str(np.random.choice(enumerations))\n",
    "            return random_value\n",
    "        else:\n",
    "            return \"\"\n",
    "            # print(f\"token: {token}\")\n",
    "            # print(f\"token_class: {token_class}\")\n",
    "            # print(f\"token values: {token_values}\")\n",
    "            # print(f\"random values: {random_value}\")\n",
    "\n",
    "    def translate_descriptor(self, descriptor):\n",
    "        text = []\n",
    "        for token in descriptor:\n",
    "            if token != \"<END>\":\n",
    "                token_class_symbol = token[:3]\n",
    "                token_class = self.class_symbols.get(token_class_symbol)\n",
    "                enumerations = []\n",
    "\n",
    "                if '|' in token:\n",
    "                    enumerations = token.split('(')[1].split(')')[0].split('|')\n",
    "                token = token[3:]\n",
    "\n",
    "                token_values = token_class.get(token)\n",
    "\n",
    "                random_value = str(np.random.choice(token_values)) if len(enumerations) == 0 else str(np.random.choice(enumerations))\n",
    "                text.append(random_value)\n",
    "                # print(f\"token: {token}\")\n",
    "                # print(f\"token_class: {token_class}\")\n",
    "                # print(f\"token values: {token_values}\")\n",
    "                # print(f\"random values: {random_value}\")\n",
    "\n",
    "        return \" \".join(text)\n",
    "                \n",
    "        \n",
    "\n",
    "    def generate_text(self, count):\n",
    "        texts_descriptors = []\n",
    "        texts = []\n",
    "        for _ in tqdm(range(count), ncols=100):\n",
    "            init_rule = np.random.choice([rule for rule in self.rules if rule.split(',')[0] == \"<START>\"])\n",
    "            prev_token, current_token = init_rule.split(\",\")[0], init_rule.split(\",\")[1]\n",
    "            \n",
    "            \n",
    "\n",
    "            next_token = \"\"\n",
    "        \n",
    "            text_descriptor = [current_token]\n",
    "\n",
    "            add = True\n",
    "            while next_token != \"<END>\":\n",
    "                new_rule = \",\".join([prev_token, current_token])\n",
    "                matching_rules = self.rules.get(new_rule)\n",
    "                if not matching_rules:\n",
    "                    add = False\n",
    "                    break\n",
    "                \n",
    "                next_token = np.random.choice(matching_rules)\n",
    "\n",
    "\n",
    "                # text += self.get_value_from_token(next_token)\n",
    "\n",
    "                #!###################################\n",
    "                text_descriptor.append(next_token)\n",
    "                #!###################################\n",
    "\n",
    "                prev_token = current_token\n",
    "                current_token = next_token\n",
    "        \n",
    "\n",
    "            if add:\n",
    "                # self.translate_descriptor(text_describer)\n",
    "                texts_descriptors.append(text_descriptor)\n",
    "                texts.append(self.translate_descriptor(text_descriptor))\n",
    "        return (texts_descriptors, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator()\n",
    "\n",
    "generated = gen.generate_text(5000000)\n",
    "descriptors, text = generated[0], generated[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"descriptors\", \"text\"])\n",
    "\n",
    "df[\"descriptors\"] = descriptors\n",
    "df[\"text\"] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./commands.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds = pd.read_csv(\"./commands.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmds['text'].drop_duplicates(keep='first').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./unique.txt\", \"w\") as unique_file:\n",
    "    cmd = \"\"\n",
    "    for text in cmds[\"text\"].unique():\n",
    "        cmd += text + \",\"\n",
    "\n",
    "    unique_file.write(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
